{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-december",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputFolder = 'images'\n",
    "# folderLen = len(inputFolder)\n",
    "# os.mkdir('images/no_target_resized')\n",
    "\n",
    "# for path, subdirs, files in os.walk(os.path.join(inputFolder,'no_target')):\n",
    "#     print(path)\n",
    "#     for name in files:\n",
    "#         print(name)\n",
    "#         image = cv2.cvtColor(cv2.imread(os.path.join(path,name)),cv2.COLOR_BGR2RGB)\n",
    "#         resized_image = cv2.resize(image,(256,256))\n",
    "#         resized_image = np.array(resized_image).astype('float32')/255\n",
    "# #         image_t = np.reshape(resized_image,[1,256,256,3])\n",
    "#         cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_image)\n",
    "    \n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-relationship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder = 'images/no_target'\n",
    "folderLen = len(inputFolder)\n",
    "os.mkdir('images/no_target_resized')\n",
    "\n",
    "inputFolder = 'images/target'\n",
    "folderLen = len(inputFolder)\n",
    "os.mkdir('images/target_resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in glob.glob(inputFolder + \"/*.jpg\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.jpeg\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.JPEG\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.png\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.webp\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in glob.glob(inputFolder + \"/*.jpg\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.jpeg\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.JPEG\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.png\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for img in glob.glob(inputFolder + \"/*.webp\"):\n",
    "    image = cv2.imread(img)\n",
    "    resized_img = cv2.resize(image,(256,256))\n",
    "    cv2.imwrite(\"images/no_target_resized\" + img[folderLen:], resized_img)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# path to the No Target image dataset\n",
    "DS_DIR = 'images/no_target_resized'\n",
    "\n",
    "# initialize empty list that we will fill out\n",
    "metadata = []\n",
    "\n",
    "# walk through directory to fill out list\n",
    "for root, dirs, files in os.walk(DS_DIR):\n",
    "    for name in files:\n",
    "        dir_name = root.split(os.path.sep)[-1]\n",
    "\n",
    "        rel_path = os.path.join(dir_name, name)\n",
    "        if 'db' not in name:\n",
    "            metadata.append([rel_path,0])\n",
    "\n",
    "#convert list to a temporary dataframe for easier manipulation\n",
    "NoTarget_df = pd.DataFrame(metadata, columns=['image', 'label'])\n",
    "\n",
    "# print(NoTarget_df.head())\n",
    "\n",
    "# path to the Target image dataset\n",
    "DS_DIR = 'images/target_resized'\n",
    "\n",
    "# initialize empty list that we will fill out\n",
    "metadata = []\n",
    "\n",
    "# walk through directory to fill out list\n",
    "for root, dirs, files in os.walk(DS_DIR):\n",
    "    for name in files:\n",
    "        dir_name = root.split(os.path.sep)[-1]\n",
    "\n",
    "        rel_path = os.path.join(dir_name, name)\n",
    "        if 'db' not in name:\n",
    "            metadata.append([rel_path, 1])\n",
    "\n",
    "#convert list to a temporary dataframe for easier manipulation\n",
    "Target_df = pd.DataFrame(metadata, columns=['image', 'label'])\n",
    "\n",
    "# print(Target_df.head())\n",
    "\n",
    "final_df = pd.concat([NoTarget_df,Target_df],axis=0)\n",
    "\n",
    "image_data = final_df['image']\n",
    "label_data = final_df['label']\n",
    "\n",
    "\n",
    "# #iterate through each\n",
    "# for value in temp_df.label.unique():\n",
    "#     target_slice = temp_df[temp_df['label'] == value].copy()\n",
    "\n",
    "#     train_ratio = 0.8\n",
    "#     val_ratio   = 0.1\n",
    "#     test_ratio = 0.1\n",
    "#     train_slice, buf_slice = train_test_split(target_slice, test_size = 1 - train_ratio, random_state=617,stratify=)\n",
    "#     test_slice, val_slice  = train_test_split(buf_slice, test_size  = val_ratio/(test_ratio + val_ratio), random_state=617)\n",
    "\n",
    "#     train_slice.loc[:, 'split'] = 'train'\n",
    "#     val_slice.loc[:, 'split']   = 'val'\n",
    "#     test_slice.loc[:, 'split']  = 'test'\n",
    "\n",
    "#     final_df = final_df.append([train_slice, val_slice, test_slice],\n",
    "#                                 ignore_index=True)\n",
    "\n",
    "# dummy_df = pd.get_dummies(final_df['label'])\n",
    "# final_df = pd.concat([final_df, dummy_df], axis=1)\n",
    "# final_df.to_csv('metadata/ACDS_190321_metadata.csv', index=False)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for Imbalance in data labels\n",
    "label_data.unique()\n",
    "label_data.groupby(label_data).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test/Train Split\n",
    "image_train, image_test, label_train, label_test = train_test_split(image_data, label_data, test_size=0.2, random_state=617,stratify=label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Initializing Resnet50 ###########################\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "def resnet50_model(classes=10, *args, **kwargs):\n",
    "    \n",
    "    #Creating Input Layer\n",
    "    input = keras.layers.Input(shape=(256,256,3))\n",
    "    \n",
    "    #Create output Layers\n",
    "    output = keras.layers.ZeroPadding2D(padding=3, name='padding_conv1')(input)\n",
    "    output = keras.layers.Conv2D(64, (7, 7), strides=(2, 2), use_bias=False, name='conv1')(output)\n",
    "    output = keras.layers.BatchNormalization(axis=3, epsilon=1e-5, name='bn_conv1')(output)\n",
    "    output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
    "    output = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='pool1')(output)\n",
    "    output = conv_block(output, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
    "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
    "    output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
    "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
    "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
    "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
    "    output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    output = keras.layers.GlobalAveragePooling2D(name='pool5')(output)\n",
    "    output = keras.layers.Dense(classes, activation='softmax', name='fc1000')(output)\n",
    "    \n",
    "    #Create a model from input and output layers\n",
    "    model = keras.models.Model(inputs = input,outputs = output, *args, **kwargs)\n",
    "    \n",
    "    #Print Model\n",
    "    print()\n",
    "    print(model.summary(),'\\n')\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', \\\n",
    "                  optimizer=keras.optimizers.adam(lr=0.01, clipnorm=0.001), \\\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating Identity Block\n",
    "def identity_block(input, kernel_size, filters, stage, block):\n",
    "    \n",
    "    #Variables\n",
    "    filters1,filters2,filters3 = filters\n",
    "    conv_name_base = 'res' +str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' +str(stage) + block + '_branch'\n",
    "\n",
    "    # Create layers\n",
    "    output = keras.layers.Conv2D(filters1, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
    "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
    "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
    "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
    "    output = keras.layers.add([output, input])\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    \n",
    "    # Return a block\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolution block\n",
    "def conv_block(input, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \n",
    "    # Variables\n",
    "    filters1, filters2, filters3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Create block layers\n",
    "    output = keras.layers.Conv2D(filters1, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
    "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
    "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
    "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
    "    shortcut = keras.layers.Conv2D(filters3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
    "    shortcut = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '1')(shortcut)\n",
    "    output = keras.layers.add([output, shortcut])\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    \n",
    "    # Return a block\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fit(image_train,label_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-sharing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-expert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
